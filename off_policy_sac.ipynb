{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 16:34:04.314110: W external/xla/xla/service/gpu/nvptx_compiler.cc:742] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Implementations of algorithms for continuous control.\"\"\"\n",
    "import functools\n",
    "from jaxrl_m.typing import *\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from jaxrl_m.common import TrainState, target_update, nonpytree_field\n",
    "from jaxrl_m.networks import Policy, Critic,OriginalCritic, ensemblize\n",
    "\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "\n",
    "class Temperature(nn.Module):\n",
    "    initial_temperature: float = 1.0\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self) -> jnp.ndarray:\n",
    "        log_temp = self.param('log_temp',\n",
    "                              init_fn=lambda key: jnp.full(\n",
    "                                  (), jnp.log(self.initial_temperature)))\n",
    "        return jnp.exp(log_temp)\n",
    "\n",
    "class SACAgent(flax.struct.PyTreeNode):\n",
    "    rng: PRNGKey\n",
    "    critic: TrainState\n",
    "    target_critic: TrainState\n",
    "    actor: TrainState\n",
    "    temp: TrainState\n",
    "    config: dict = nonpytree_field()\n",
    "\n",
    "    @jax.jit\n",
    "    def update(agent, batch: Batch):\n",
    "        new_rng, curr_key, next_key = jax.random.split(agent.rng, 3)\n",
    "\n",
    "        def critic_loss_fn(critic_params):\n",
    "            next_dist = agent.actor(batch['next_observations'])\n",
    "            next_actions, next_log_probs = next_dist.sample_and_log_prob(seed=next_key)\n",
    "\n",
    "            next_q1, next_q2 = agent.target_critic(batch['next_observations'], next_actions)\n",
    "            next_q = jnp.minimum(next_q1, next_q2)\n",
    "            target_q = batch['rewards'] + agent.config['discount'] * batch['masks'] * next_q\n",
    "\n",
    "            if agent.config['backup_entropy']:\n",
    "                target_q = target_q - agent.config['discount'] * batch['masks'] * next_log_probs * agent.temp()\n",
    "            \n",
    "            q1, q2 = agent.critic(batch['observations'], batch['actions'], params=critic_params)\n",
    "            critic_loss = ((q1 - target_q)**2 + (q2 - target_q)**2).mean()\n",
    "            \n",
    "            return critic_loss, {\n",
    "                'critic_loss': critic_loss,\n",
    "                'q1': q1.mean(),\n",
    "            }        \n",
    "\n",
    "        def actor_loss_fn(actor_params):\n",
    "            dist = agent.actor(batch['observations'], params=actor_params)\n",
    "            actions, log_probs = dist.sample_and_log_prob(seed=curr_key)\n",
    "            \n",
    "            q1, q2 = agent.critic(batch['observations'], actions)\n",
    "            q = jnp.minimum(q1, q2)\n",
    "\n",
    "            actor_loss = (log_probs * agent.temp() - q).mean()\n",
    "            return actor_loss, {\n",
    "                'actor_loss': actor_loss,\n",
    "                'entropy': -1 * log_probs.mean(),\n",
    "            }\n",
    "        \n",
    "        def temp_loss_fn(temp_params, entropy, target_entropy):\n",
    "            temperature = agent.temp(params=temp_params)\n",
    "            temp_loss = (temperature * (entropy - target_entropy)).mean()\n",
    "            return temp_loss, {\n",
    "                'temp_loss': temp_loss,\n",
    "                'temperature': temperature,\n",
    "            }\n",
    "        \n",
    "        new_critic, critic_info = agent.critic.apply_loss_fn(loss_fn=critic_loss_fn, has_aux=True)\n",
    "        new_target_critic = target_update(agent.critic, agent.target_critic, agent.config['target_update_rate'])\n",
    "        new_actor, actor_info = agent.actor.apply_loss_fn(loss_fn=actor_loss_fn, has_aux=True)\n",
    "\n",
    "        temp_loss_fn = functools.partial(temp_loss_fn, entropy=actor_info['entropy'], target_entropy=agent.config['target_entropy'])\n",
    "        new_temp, temp_info = agent.temp.apply_loss_fn(loss_fn=temp_loss_fn, has_aux=True)\n",
    "\n",
    "        return agent.replace(rng=new_rng, critic=new_critic, target_critic=new_target_critic, actor=new_actor, temp=new_temp), {\n",
    "            **critic_info, **actor_info, **temp_info}\n",
    "\n",
    "    @jax.jit\n",
    "    def sample_actions(agent,   \n",
    "                       observations: np.ndarray,\n",
    "                       seed: PRNGKey,\n",
    "                       random = bool,\n",
    "                       temperature: float = 1.0,\n",
    "                       ) -> jnp.ndarray:\n",
    "        actions = agent.actor(observations, temperature=temperature).sample(seed=seed)\n",
    "        \n",
    "        return actions\n",
    "\n",
    "\n",
    "\n",
    "def create_learner(\n",
    "                 seed: int,\n",
    "                 observations: jnp.ndarray,\n",
    "                 actions: jnp.ndarray,\n",
    "                 actor_lr: float = 3e-4,\n",
    "                 critic_lr: float = 3e-4,\n",
    "                 temp_lr: float = 3e-4,\n",
    "                 hidden_dims: Sequence[int] = (256, 256),\n",
    "                 discount: float = 0.99,\n",
    "                 tau: float = 0.005,\n",
    "                 target_entropy: float = None,\n",
    "                 backup_entropy: bool = True,\n",
    "            **kwargs):\n",
    "\n",
    "        print('Extra kwargs:', kwargs)\n",
    "\n",
    "        rng = jax.random.PRNGKey(seed)\n",
    "        rng, actor_key, critic_key = jax.random.split(rng, 3)\n",
    "\n",
    "        action_dim = actions.shape[-1]\n",
    "        actor_def = Policy(hidden_dims, action_dim=action_dim, \n",
    "            log_std_min=-10.0, state_dependent_std=True, tanh_squash_distribution=True, final_fc_init_scale=1.0)\n",
    "\n",
    "        actor_params = actor_def.init(actor_key, observations)['params']\n",
    "        actor = TrainState.create(actor_def, actor_params, tx=optax.adam(learning_rate=actor_lr))\n",
    "\n",
    "        critic_def = ensemblize(OriginalCritic, num_qs=2)(hidden_dims)\n",
    "        critic_params = critic_def.init(critic_key, observations, actions)['params']\n",
    "        critic = TrainState.create(critic_def, critic_params, tx=optax.adam(learning_rate=critic_lr))\n",
    "        target_critic = TrainState.create(critic_def, critic_params)\n",
    "\n",
    "        temp_def = Temperature()\n",
    "        temp_params = temp_def.init(rng)['params']\n",
    "        temp = TrainState.create(temp_def, temp_params, tx=optax.adam(learning_rate=temp_lr))\n",
    "\n",
    "        if target_entropy is None:\n",
    "            #target_entropy = -0.5 * action_dim\n",
    "            target_entropy = - action_dim\n",
    "\n",
    "        config = flax.core.FrozenDict(dict(\n",
    "            discount=discount,\n",
    "            target_update_rate=tau,\n",
    "            target_entropy=target_entropy,\n",
    "            backup_entropy=backup_entropy,            \n",
    "        ))\n",
    "\n",
    "        return SACAgent(rng, critic=critic, target_critic=target_critic, actor=actor, temp=temp, config=config)\n",
    "\n",
    "def get_default_config():\n",
    "    import ml_collections\n",
    "\n",
    "    return ml_collections.ConfigDict({\n",
    "        'actor_lr': 3e-4,\n",
    "        'critic_lr': 3e-4,\n",
    "        'temp_lr': 3e-4,\n",
    "        'hidden_dims': (256, 256),\n",
    "        'discount': 0.99,\n",
    "        'tau': 0.005,\n",
    "        'target_entropy': ml_collections.config_dict.placeholder(float),\n",
    "        'backup_entropy': True,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/tmpowpnek3u/wandb/run-20240307_163405-sac_test_sac_HalfCheetah-v5_20240307_163404</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mahdikallel/v5/runs/sac_test_sac_HalfCheetah-v5_20240307_163404' target=\"_blank\">sac_HalfCheetah-v5</a></strong> to <a href='https://wandb.ai/mahdikallel/v5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mahdikallel/v5' target=\"_blank\">https://wandb.ai/mahdikallel/v5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mahdikallel/v5/runs/sac_test_sac_HalfCheetah-v5_20240307_163404' target=\"_blank\">https://wandb.ai/mahdikallel/v5/runs/sac_test_sac_HalfCheetah-v5_20240307_163404</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra kwargs: {'max_steps': 1000000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8016/1000000 [00:00<00:49, 19999.96it/s]Finished tracing + transforming <lambda> for pjit in 0.0011332035064697266 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002429485321044922 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001800060272216797 sec\n",
      "Finished tracing + transforming _reduce_sum for pjit in 0.00020074844360351562 sec\n",
      "Finished tracing + transforming _mean for pjit in 0.0008251667022705078 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00016260147094726562 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00018525123596191406 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00021886825561523438 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001876354217529297 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002384185791015625 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00015664100646972656 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00015020370483398438 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002224445343017578 sec\n",
      "Finished tracing + transforming tanh for pjit in 0.00011134147644042969 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0009672641754150391 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022149085998535156 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023174285888671875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022149085998535156 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008673667907714844 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00021982192993164062 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00014972686767578125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008969306945800781 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022459030151367188 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0001678466796875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00019240379333496094 sec\n",
      "Finished tracing + transforming clip for pjit in 0.001203775405883789 sec\n",
      "Finished tracing + transforming exp for pjit in 0.00012087821960449219 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001659393310546875 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.0001804828643798828 sec\n",
      "Finished tracing + transforming absolute for pjit in 0.00010728836059570312 sec\n",
      "Finished tracing + transforming log for pjit in 0.00011420249938964844 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.000156402587890625 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00015974044799804688 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016164779663085938 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001595020294189453 sec\n",
      "Finished tracing + transforming _uniform for pjit in 0.0024678707122802734 sec\n",
      "Finished tracing + transforming _normal_real for pjit in 0.002985715866088867 sec\n",
      "Finished tracing + transforming _normal for pjit in 0.003463268280029297 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001735687255859375 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0002269744873046875 sec\n",
      "Finished tracing + transforming square for pjit in 0.00011754035949707031 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0001690387725830078 sec\n",
      "Finished tracing + transforming _reduce_sum for pjit in 0.00027108192443847656 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001595020294189453 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016617774963378906 sec\n",
      "Finished tracing + transforming _reduce_sum for pjit in 0.00019359588623046875 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001533031463623047 sec\n",
      "Finished tracing + transforming tanh for pjit in 0.0001220703125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00017023086547851562 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00017595291137695312 sec\n",
      "Finished tracing + transforming logaddexp for pjit in 0.0003638267517089844 sec\n",
      "Finished tracing + transforming softplus for pjit in 0.0010423660278320312 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00015091896057128906 sec\n",
      "Finished tracing + transforming run_setup_only for pjit in 0.00016260147094726562 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0009291172027587891 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023126602172851562 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022912025451660156 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022077560424804688 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008747577667236328 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022602081298828125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023055076599121094 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023126602172851562 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008947849273681641 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022482872009277344 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016236305236816406 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0001556873321533203 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016927719116210938 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00022149085998535156 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00021147727966308594 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00028634071350097656 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001685619354248047 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002923011779785156 sec\n",
      "Finished tracing + transforming run_setup_only for pjit in 0.00016355514526367188 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0009350776672363281 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022935867309570312 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022983551025390625 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023889541625976562 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008969306945800781 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022935867309570312 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002410411834716797 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002276897430419922 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008041858673095703 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002295970916748047 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00015354156494140625 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00014710426330566406 sec\n",
      "Finished tracing + transforming _reduce_sum for pjit in 0.0001938343048095703 sec\n",
      "Finished tracing + transforming _mean for pjit in 0.0007698535919189453 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001697540283203125 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001685619354248047 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00015115737915039062 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016379356384277344 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00023031234741210938 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001704692840576172 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001575946807861328 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001621246337890625 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00015306472778320312 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001838207244873047 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00019693374633789062 sec\n",
      "Finished tracing + transforming _broadcast_arrays for pjit in 8.511543273925781e-05 sec\n",
      "Finished tracing + transforming _where for pjit in 0.0005488395690917969 sec\n",
      "Finished tracing + transforming _power for pjit in 0.00020384788513183594 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00018215179443359375 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00022029876708984375 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.000152587890625 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.0001518726348876953 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015616416931152344 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00014495849609375 sec\n",
      "Finished tracing + transforming bias_correction for pjit in 0.004502534866333008 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00018525123596191406 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00018548965454101562 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015354156494140625 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00017595291137695312 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00012087821960449219 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.000152587890625 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001678466796875 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00011467933654785156 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.0001533031463623047 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016570091247558594 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00011515617370605469 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.000148773193359375 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016260147094726562 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00011277198791503906 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015091896057128906 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016307830810546875 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016760826110839844 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016736984252929688 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0005037784576416016 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001773834228515625 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016927719116210938 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0009548664093017578 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023031234741210938 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022864341735839844 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022792816162109375 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008616447448730469 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022983551025390625 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023174285888671875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00027441978454589844 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008435249328613281 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002219676971435547 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008223056793212891 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022983551025390625 sec\n",
      "Finished tracing + transforming logaddexp for pjit in 0.0003077983856201172 sec\n",
      "Finished tracing + transforming real for pjit in 6.890296936035156e-05 sec\n",
      "Finished tracing + transforming real for pjit in 0.0001232624053955078 sec\n",
      "Finished tracing + transforming run_setup_only for pjit in 0.00017118453979492188 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0009679794311523438 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023126602172851562 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00024056434631347656 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.000240325927734375 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008289813995361328 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023102760314941406 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00024366378784179688 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023698806762695312 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008404254913330078 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022554397583007812 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0003066062927246094 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022149085998535156 sec\n",
      "Finished tracing + transforming _reduce_sum for pjit in 0.00019621849060058594 sec\n",
      "Finished tracing + transforming _mean for pjit in 0.0008401870727539062 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001900196075439453 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00017571449279785156 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00015163421630859375 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00015354156494140625 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015783309936523438 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.0001583099365234375 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015997886657714844 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.0001544952392578125 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015425682067871094 sec\n",
      "Finished tracing + transforming bias_correction for pjit in 0.003806591033935547 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00023436546325683594 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00012445449829101562 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015878677368164062 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00017380714416503906 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00012135505676269531 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015854835510253906 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00022411346435546875 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00011873245239257812 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015473365783691406 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001697540283203125 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.000118255615234375 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.000156402587890625 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00017786026000976562 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00011658668518066406 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.0003859996795654297 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.07932066917419434 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022864341735839844 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001938343048095703 sec\n",
      "Finished tracing + transforming _reduce_sum for pjit in 0.00022482872009277344 sec\n",
      "Finished tracing + transforming _mean for pjit in 0.0009264945983886719 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00015735626220703125 sec\n",
      "Finished tracing + transforming fn for pjit in 0.000164031982421875 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00018167495727539062 sec\n",
      "Finished tracing + transforming bias_correction for pjit in 0.0009899139404296875 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00017690658569335938 sec\n",
      "Finished tracing + transforming sqrt for pjit in 0.00012350082397460938 sec\n",
      "Finished tracing + transforming true_divide for pjit in 0.00015211105346679688 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00017189979553222656 sec\n",
      "Finished tracing + transforming update for pjit in 0.3444998264312744 sec\n",
      "Compiling update for with global shapes and types [ShapedArray(uint32[2]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(int32[]), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[17,256]), ShapedArray(float32[256]), ShapedArray(float32[256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(int32[]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[17,256]), ShapedArray(float32[256]), ShapedArray(float32[256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[17,256]), ShapedArray(float32[256]), ShapedArray(float32[256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(int32[]), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[256,17]), ShapedArray(float32[256,17]), ShapedArray(float32[256])]. Argument mapping: (GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated})).\n",
      "Finished tracing + transforming _threefry_random_bits_original for pjit in 0.0003638267517089844 sec\n",
      "Finished jaxpr to MLIR module conversion jit(update) in 0.07639193534851074 sec\n",
      "Finished XLA compilation of jit(update) in 4.0680482387542725 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0010833740234375 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00024366378784179688 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022649765014648438 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022673606872558594 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008797645568847656 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022125244140625 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00021982192993164062 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022029876708984375 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0009233951568603516 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.000225067138671875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008006095886230469 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002205371856689453 sec\n",
      "Finished tracing + transforming run_setup_only for pjit in 0.0001697540283203125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0009179115295410156 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002338886260986328 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023031234741210938 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023698806762695312 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008041858673095703 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002257823944091797 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002257823944091797 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002377033233642578 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008416175842285156 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022792816162109375 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00028514862060546875 sec\n",
      "Finished tracing + transforming exp for pjit in 0.00012969970703125 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00016117095947265625 sec\n",
      "Finished tracing + transforming run_setup_only for pjit in 0.00015735626220703125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008599758148193359 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022602081298828125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002276897430419922 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002276897430419922 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008037090301513672 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022530555725097656 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023889541625976562 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023174285888671875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008528232574462891 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023412704467773438 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.000985860824584961 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002307891845703125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002841949462890625 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002288818359375 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008234977722167969 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023055076599121094 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022912025451660156 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022840499877929688 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008096694946289062 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022268295288085938 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008690357208251953 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002231597900390625 sec\n",
      "Finished tracing + transforming run_setup_only for pjit in 0.0001575946807861328 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008494853973388672 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023102760314941406 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023412704467773438 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022935867309570312 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008113384246826172 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022840499877929688 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023293495178222656 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002334117889404297 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0007944107055664062 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022912025451660156 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00028634071350097656 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002884864807128906 sec\n",
      "Finished tracing + transforming fn for pjit in 0.0001533031463623047 sec\n",
      "Finished tracing + transforming bias_correction for pjit in 0.0004227161407470703 sec\n",
      "Finished tracing + transforming fn for pjit in 0.00015735626220703125 sec\n",
      "Finished tracing + transforming update for pjit in 0.15296483039855957 sec\n",
      "Compiling update for with global shapes and types [ShapedArray(uint32[2]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(int32[]), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[17,256]), ShapedArray(float32[256]), ShapedArray(float32[256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(int32[]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[17,256]), ShapedArray(float32[256]), ShapedArray(float32[256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[17,256]), ShapedArray(float32[256]), ShapedArray(float32[256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[]), ShapedArray(int32[]), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[256,17]), ShapedArray(float32[256,17]), ShapedArray(float32[256])]. Argument mapping: (GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated})).\n",
      "Finished jaxpr to MLIR module conversion jit(update) in 0.07786870002746582 sec\n",
      "Finished XLA compilation of jit(update) in 1.4213640689849854 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0011036396026611328 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002410411834716797 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.000232696533203125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022935867309570312 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008716583251953125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002257823944091797 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002224445343017578 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022840499877929688 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.000850677490234375 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002200603485107422 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008702278137207031 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002281665802001953 sec\n",
      "Finished tracing + transforming run_setup_only for pjit in 0.00016498565673828125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0009198188781738281 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023794174194335938 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00028777122497558594 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002276897430419922 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008099079132080078 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023174285888671875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002238750457763672 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022149085998535156 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008425712585449219 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002269744873046875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002868175506591797 sec\n",
      "Finished tracing + transforming run_setup_only for pjit in 0.0001556873321533203 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008594989776611328 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023317337036132812 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023889541625976562 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002319812774658203 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0007994174957275391 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002276897430419922 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023126602172851562 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00024008750915527344 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.000835418701171875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00022840499877929688 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0009875297546386719 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023651123046875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002951622009277344 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002338886260986328 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008332729339599609 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.000225067138671875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023221969604492188 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002307891845703125 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008227825164794922 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023221969604492188 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008788108825683594 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023651123046875 sec\n",
      "Finished tracing + transforming run_setup_only for pjit in 0.0001628398895263672 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008943080902099609 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023484230041503906 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002415180206298828 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023174285888671875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0007956027984619141 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002357959747314453 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.00023651123046875 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002276897430419922 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0008208751678466797 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.000247955322265625 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002887248992919922 sec\n",
      "Finished tracing + transforming <lambda> for pjit in 0.0002989768981933594 sec\n",
      "Finished tracing + transforming update for pjit in 0.1509103775024414 sec\n",
      "Compiling update for with global shapes and types [ShapedArray(uint32[2]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(int32[]), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[2,256]), ShapedArray(float32[2,23,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256,256]), ShapedArray(float32[2,2]), ShapedArray(float32[2,256,2]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(float32[2,256]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[17,256]), ShapedArray(float32[256]), ShapedArray(float32[256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(int32[]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[17,256]), ShapedArray(float32[256]), ShapedArray(float32[256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[6]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[17,256]), ShapedArray(float32[256]), ShapedArray(float32[256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(int32[], weak_type=True), ShapedArray(float32[]), ShapedArray(int32[]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[256,6]), ShapedArray(float32[256]), ShapedArray(float32[256,17]), ShapedArray(float32[256,17]), ShapedArray(float32[256])]. Argument mapping: (GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated}), GSPMDSharding({replicated})).\n",
      "Finished jaxpr to MLIR module conversion jit(update) in 0.07593202590942383 sec\n",
      "Finished XLA compilation of jit(update) in 1.4207162857055664 sec\n",
      "  3%|▎         | 28093/1000000 [00:29<16:51, 960.94it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39msample_actions(obs, seed\u001b[38;5;241m=\u001b[39mkey)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#next_obs, reward, done, info = env.step(action)\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m next_obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeLimit.truncated\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m info)\n\u001b[1;32m     79\u001b[0m replay_buffer\u001b[38;5;241m.\u001b[39madd_transition(\u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     80\u001b[0m     observations\u001b[38;5;241m=\u001b[39mobs,\n\u001b[1;32m     81\u001b[0m     actions\u001b[38;5;241m=\u001b[39maction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     next_observations\u001b[38;5;241m=\u001b[39mnext_obs,\n\u001b[1;32m     85\u001b[0m ))\n",
      "File \u001b[0;32m~/Desktop/supersac/jaxrl_m/evaluation.py:148\u001b[0m, in \u001b[0;36mEpisodeMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# observation, reward, done, info = self.env.step(action)\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     observation, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_length \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:121\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:381\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/gymnasium/core.py:290\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:279\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/gymnasium/envs/mujoco/half_cheetah_v5.py:232\u001b[0m, in \u001b[0;36mHalfCheetahEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    229\u001b[0m x_velocity \u001b[38;5;241m=\u001b[39m (x_position_after \u001b[38;5;241m-\u001b[39m x_position_before) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n\u001b[1;32m    231\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_obs()\n\u001b[0;32m--> 232\u001b[0m reward, reward_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_rew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_velocity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_position_after, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_velocity\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_velocity, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreward_info}\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/gymnasium/envs/mujoco/half_cheetah_v5.py:242\u001b[0m, in \u001b[0;36mHalfCheetahEnv._get_rew\u001b[0;34m(self, x_velocity, action)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_rew\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_velocity: \u001b[38;5;28mfloat\u001b[39m, action):\n\u001b[1;32m    241\u001b[0m     forward_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reward_weight \u001b[38;5;241m*\u001b[39m x_velocity\n\u001b[0;32m--> 242\u001b[0m     ctrl_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     reward \u001b[38;5;241m=\u001b[39m forward_reward \u001b[38;5;241m-\u001b[39m ctrl_cost\n\u001b[1;32m    246\u001b[0m     reward_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m: forward_reward,\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward_ctrl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39mctrl_cost,\n\u001b[1;32m    249\u001b[0m     }\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/gymnasium/envs/mujoco/half_cheetah_v5.py:222\u001b[0m, in \u001b[0;36mHalfCheetahEnv.control_cost\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontrol_cost\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m--> 222\u001b[0m     control_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctrl_cost_weight \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m control_cost\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/array.py:402\u001b[0m, in \u001b[0;36mArrayImpl.__array__\u001b[0;34m(self, dtype, context)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Is this Array fully addressable?\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m  A jax.Array is fully addressable if the current process can address all of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m  not fully addressable.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharding\u001b[38;5;241m.\u001b[39mis_fully_addressable\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    403\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__dlpack__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, stream: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import jax\n",
    "import tqdm\n",
    "import gymnasium as gym\n",
    "\n",
    "#import examples.mujoco.sac as learner\n",
    "\n",
    "from jaxrl_m.wandb import setup_wandb, default_wandb_config, get_flag_dict\n",
    "import wandb\n",
    "from jaxrl_m.evaluation import supply_rng, evaluate, flatten, EpisodeMonitor\n",
    "from jaxrl_m.dataset import ReplayBuffer\n",
    "from jaxrl_m.rollout import rollout_policy2,rollout_policy\n",
    "#from ml_collections import config_flags\n",
    "import pickle\n",
    "#from flax.training import checkpoints\n",
    "\n",
    "\n",
    "#FLAGS = flags.FLAGS\n",
    "env_name='HalfCheetah-v5'\n",
    "seed=np.random.choice(1000000)\n",
    "eval_episodes=10\n",
    "batch_size = 256\n",
    "max_steps = int(1e6)\n",
    "start_steps = int(1e4)                     \n",
    "log_interval = 10000\n",
    "eval_interval = 10000\n",
    "\n",
    "wandb_config = default_wandb_config()\n",
    "wandb_config.update({\n",
    "    'project': 'v5',\n",
    "    'group': 'sac_test',\n",
    "    'name': f'sac_{env_name}',\n",
    "})\n",
    "\n",
    "\n",
    "env = EpisodeMonitor(gym.make(env_name))\n",
    "eval_env = EpisodeMonitor(gym.make(env_name))\n",
    "setup_wandb(**wandb_config,hyperparam_dict={})\n",
    "\n",
    "example_transition = dict(\n",
    "    observations=env.observation_space.sample(),\n",
    "    actions=env.action_space.sample(),\n",
    "    rewards=0.0,\n",
    "    masks=1.0,\n",
    "    next_observations=env.observation_space.sample(),\n",
    ")\n",
    "\n",
    "replay_buffer = ReplayBuffer.create(example_transition, size=int(1e6))\n",
    "placeholder = ReplayBuffer.create(example_transition, size=int(1e6))\n",
    "\n",
    "agent = create_learner(seed,\n",
    "                example_transition['observations'][None],\n",
    "                example_transition['actions'][None],\n",
    "                max_steps=max_steps,\n",
    "                #**FLAGS.config\n",
    "                )\n",
    "\n",
    "exploration_metrics = dict()\n",
    "obs,info = env.reset()    \n",
    "exploration_rng = jax.random.PRNGKey(0)\n",
    "\n",
    "for i in tqdm.tqdm(range(1, max_steps + 1),\n",
    "                    smoothing=0.1,\n",
    "                    dynamic_ncols=True):\n",
    "\n",
    "    if i < start_steps:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        exploration_rng, key = jax.random.split(exploration_rng)\n",
    "        action = agent.sample_actions(obs, seed=key)\n",
    "\n",
    "    #next_obs, reward, done, info = env.step(action)\n",
    "    next_obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    mask = float(not done or 'TimeLimit.truncated' in info)\n",
    "    \n",
    "    replay_buffer.add_transition(dict(\n",
    "        observations=obs,\n",
    "        actions=action,\n",
    "        rewards=reward,\n",
    "        masks=mask,\n",
    "        next_observations=next_obs,\n",
    "    ))\n",
    "    obs = next_obs\n",
    "\n",
    "    if (done or truncated):\n",
    "        exploration_metrics = {f'exploration/{k}': v for k, v in flatten(info).items()}\n",
    "        obs,info= env.reset()\n",
    "\n",
    "    if replay_buffer.size < start_steps:\n",
    "        continue\n",
    "\n",
    "    batch = replay_buffer.sample(batch_size)  \n",
    "    \n",
    "    with jax.log_compiles(True):\n",
    "        agent, update_info = agent.update(batch)\n",
    "\n",
    "    if i % log_interval == 0:\n",
    "        train_metrics = {f'training/{k}': v for k, v in update_info.items()}\n",
    "        wandb.log(train_metrics, step=i)\n",
    "        wandb.log(exploration_metrics, step=i)\n",
    "        exploration_metrics = dict()\n",
    "\n",
    "    if i % eval_interval == 0:\n",
    "        \n",
    "        \n",
    "        policy_fn = partial(supply_rng(agent.sample_actions), temperature=0.0)\n",
    "        eval_info = evaluate(policy_fn, eval_env, num_episodes=eval_episodes)\n",
    "        eval_metrics = {f'evaluation/{k}': v for k, v in eval_info.items()}\n",
    "        # _,_,_,disc_policy_return,_,undisc_policy_return_e,_ = rollout_policy(agent,eval_env,exploration_rng,\n",
    "        #                                                         None,None,warmup=False,\n",
    "        #                                                         num_rollouts=10,random=False,\n",
    "        #                                                     )\n",
    "        # eval_info = {'disc_policy_return': disc_policy_return,'undisc_policy_return': undisc_policy_return_e}\n",
    "        # eval_metrics = {f'evaluation/{k}': v for k, v in eval_info.items()}\n",
    "        wandb.log(eval_metrics, step=int(i),commit=True)\n",
    "        #wandb.log(eval_metrics, step=i)\n",
    "\n",
    "    # if i % FLAGS.save_interval == 0 and FLAGS.save_dir is not None:\n",
    "    #     checkpoints.save_checkpoint(FLAGS.save_dir, agent, i)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
