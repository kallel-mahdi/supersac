{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementations of algorithms for continuous control.\"\"\"\n",
    "import functools\n",
    "from jaxrl_m.typing import *\n",
    "\n",
    "import jax\n",
    "import jax.lax as lax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from jaxrl_m.common import TrainState, target_update, nonpytree_field\n",
    "from jaxrl_m.networks import Policy, Critic, ensemblize\n",
    "\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from functools import partial\n",
    "\n",
    "NUM_ROLLOUTS = 10\n",
    "NUM_CRITICS = 5\n",
    "\n",
    "class Temperature(nn.Module):\n",
    "    initial_temperature: float = 1e-3\n",
    "\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self) -> jnp.ndarray:\n",
    "        log_temp = self.param('log_temp',\n",
    "                              init_fn=lambda key: jnp.full(\n",
    "                                  (), self.initial_temperature))\n",
    "        return jnp.abs(log_temp)\n",
    "        \n",
    "\n",
    "class SACAgent(flax.struct.PyTreeNode):\n",
    "    rng: PRNGKey\n",
    "    critic: TrainState\n",
    "    target_critic: TrainState\n",
    "    actor: TrainState\n",
    "    temp: TrainState\n",
    "    config: dict = nonpytree_field()\n",
    "    \n",
    "    \n",
    "    @jax.jit    \n",
    "    def reset_critic_optimizer(agent):\n",
    "    \n",
    "        new_opt_state = agent.critic.tx.init(agent.critic.params)\n",
    "        new_critic = agent.critic.replace(opt_state=new_opt_state)\n",
    "        \n",
    "        return agent.replace(critic=new_critic)\n",
    "\n",
    "    @partial(jax.jit,static_argnames=('num_steps',))  \n",
    "    def update_many_critics(agent,transitions: Batch,idxs:jnp.array,num_steps:int,R2):\n",
    "\n",
    "        def update_one_critic(critic,idxs,\n",
    "                            agent,transitions,num_steps):\n",
    "            \n",
    "            def one_update(agent,critic,batch: Batch):\n",
    "                                  \n",
    "                def critic_loss_fn(critic_params):\n",
    "                            \n",
    "                            \n",
    "                            next_dist = agent.actor(batch['next_observations'])\n",
    "                            next_actions, next_log_probs = next_dist.sample_and_log_prob(seed=next_key)\n",
    "\n",
    "                            concat_actions = jnp.concatenate([batch[\"actions\"],next_actions])\n",
    "                            concat_observations = jnp.concatenate([batch[\"observations\"],batch[\"next_observations\"]])\n",
    "                            \n",
    "                            concat_q = agent.critic(concat_observations, concat_actions,\n",
    "                                                    True,params=critic_params)\n",
    "                            q,next_q = jnp.split(concat_q,2,axis=0) ## axis=1 for ensemble\n",
    "                            target_q = batch['rewards'] + agent.config['discount'] * batch['masks'] * next_q\n",
    "                            \n",
    "                            # if agent.config['backup_entropy']:\n",
    "                            #     target_q = target_q - agent.config['discount'] * batch['masks'] * next_log_probs * agent.temp()\n",
    "                                \n",
    "                            target_q = jax.lax.stop_gradient(target_q)\n",
    "                            critic_loss = ((target_q-q)**2).mean()\n",
    "                            \n",
    "                            return critic_loss, {\n",
    "                            'critic_loss': critic_loss,\n",
    "                            'q1': q.mean(),\n",
    "                        }  \n",
    "                    \n",
    "        \n",
    "                new_critic, critic_info = critic.apply_loss_fn(loss_fn=critic_loss_fn, has_aux=True)\n",
    "                \n",
    "                return agent,new_critic\n",
    "            \n",
    "            \n",
    "            get_batch = lambda transitions,idx : jax.tree_map(lambda x : x[idx],transitions)\n",
    "                \n",
    "            agent,new_critic = jax.lax.fori_loop(0, num_steps, \n",
    "                        lambda i, args: one_update(*args,get_batch(transitions,idxs[i])),\n",
    "                        (agent,critic))\n",
    "            \n",
    "            return new_critic\n",
    "        \n",
    "        \n",
    "        new_rng, curr_key, next_key = jax.random.split(agent.rng, 3)\n",
    "        critic = agent.critic\n",
    "        \n",
    "        ###### Reset critic params ######\n",
    "        \n",
    "        reset = lambda rng,params : critic.init(rng,\n",
    "                                                agent.config[\"observations\"], agent.config[\"actions\"],False)[\"params\"]\n",
    "        no_reset = lambda rng,params: params\n",
    "        f = lambda  mask,rng,params :lax.cond(mask,reset,no_reset,rng,params)\n",
    "        mask = jnp.zeros((NUM_CRITICS))\n",
    "        mask.at[jnp.argmin(R2)].set(1)\n",
    "        rngs = jax.random.split(agent.rng, NUM_CRITICS)\n",
    "        critic_params = jax.vmap(f,in_axes=(0,0,0))(mask,rngs,critic.params)\n",
    "        ###################################\n",
    "        critic_def = Critic((256,256))\n",
    "        critics = jax.vmap(TrainState.create,in_axes=(None,0,None))(critic_def,critic_params,optax.adam(learning_rate=3e-4))\n",
    "        tmp = partial(update_one_critic,agent=agent,transitions=transitions,num_steps=num_steps)\n",
    "        new_critics = jax.vmap(tmp,in_axes=(0,0))(critics,idxs)\n",
    "        agent = agent.replace(rng=new_rng,critic=new_critics)\n",
    "        \n",
    "        return agent,{}\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    @jax.jit\n",
    "    def update_actor(agent, batch: Batch,R2):\n",
    "        new_rng, curr_key, next_key = jax.random.split(agent.rng, 3)\n",
    "\n",
    "        def actor_loss_fn(actor_params,R2):\n",
    "            observations = jnp.repeat(batch['observations'], 10, axis=0)\n",
    "            discounts = jnp.repeat(batch['discounts'], 10, axis=0)\n",
    "            masks = jnp.int32(jnp.repeat(batch['masks'], 10, axis=0))\n",
    "\n",
    "            dist = agent.actor(observations, params=actor_params)\n",
    "            actions, log_probs = dist.sample_and_log_prob(seed=curr_key)\n",
    "            call_one_critic = lambda observations,actions,params : agent.critic(observations,actions,params=params)\n",
    "            q_all = jax.vmap(call_one_critic,in_axes=(None,None,0))(observations, actions,agent.critic.params)##critic\n",
    "            q_weights = jax.nn.softmax(R2,axis=0)\n",
    "            q = jnp.sum(q_weights.reshape(-1,1)*q_all,axis=0)\n",
    "            \n",
    "            actor_loss = (discounts*(log_probs * agent.temp() - q)).sum()/discounts.sum()\n",
    "            # lr_bonus = jnp.exp(jnp.max(R2))/jnp.exp(1)\n",
    "            # actor_loss = actor_loss*lr_bonus\n",
    "           \n",
    "            return actor_loss, {\n",
    "                'actor_loss': actor_loss,\n",
    "                'entropy': -1 * ((discounts*log_probs)/jnp.sum(discounts)).sum(),\n",
    "                #'entropy': -1 * log_probs.mean(),\n",
    "            }\n",
    "        \n",
    "        \n",
    "        def temp_loss_fn(temp_params, entropy, target_entropy):\n",
    "            temperature = agent.temp(params=temp_params)\n",
    "            entropy_diff = entropy-target_entropy\n",
    "            temp_loss = (temperature * entropy_diff).mean()\n",
    "            return temp_loss, {\n",
    "                'temp_loss': temp_loss,\n",
    "                'temperature': temperature,\n",
    "                'entropy_diff': entropy_diff,\n",
    "            }\n",
    "\n",
    "        loss_fn = partial(actor_loss_fn,R2=R2)\n",
    "        new_actor, actor_info = agent.actor.apply_loss_fn(loss_fn=loss_fn, has_aux=True)\n",
    "        temp_loss_fn = functools.partial(temp_loss_fn, entropy=actor_info['entropy'], target_entropy=agent.config['target_entropy'])\n",
    "        new_temp, temp_info = agent.temp.apply_loss_fn(loss_fn=temp_loss_fn, has_aux=True)\n",
    "        new_temp.params[\"log_temp\"]=jnp.clip(new_temp.params[\"log_temp\"],1e-6,1)\n",
    "        agent = agent.replace(rng=new_rng, temp=new_temp)\n",
    "        new_actor, actor_info = agent.actor.apply_loss_fn(loss_fn=loss_fn, has_aux=True)\n",
    "        \n",
    "        return agent.replace(rng=new_rng, actor=new_actor), {**actor_info, **temp_info}\n",
    "\n",
    "    @jax.jit\n",
    "    def sample_actions(agent,   \n",
    "                       observations: np.ndarray,\n",
    "                       seed: PRNGKey,\n",
    "                       random = bool,\n",
    "                       temperature: float = 1.0,\n",
    "                       ) -> jnp.ndarray:\n",
    "        actions = agent.actor(observations, temperature=temperature).sample(seed=seed)\n",
    "        \n",
    "        return actions\n",
    "\n",
    "\n",
    "\n",
    "def create_learner(\n",
    "                 seed: int,\n",
    "                 observations: jnp.ndarray,\n",
    "                 actions: jnp.ndarray,\n",
    "                 actor_lr: float = 3e-4,\n",
    "                 critic_lr: float = 3e-4,\n",
    "                 temp_lr: float =3e-1,## Test\n",
    "                 hidden_dims: Sequence[int] = (256, 256),\n",
    "                 discount: float = 0.99,\n",
    "                 tau: float = 0.005,\n",
    "                 target_entropy: float = None,\n",
    "                 backup_entropy: bool = True,\n",
    "            **kwargs):\n",
    "\n",
    "        print('Extra kwargs:', kwargs)\n",
    "\n",
    "        rng = jax.random.PRNGKey(seed)\n",
    "        rng, actor_key, critic_key = jax.random.split(rng, 3)\n",
    "\n",
    "        action_dim = actions.shape[-1]\n",
    "        actor_def = Policy((256,256), action_dim=action_dim, \n",
    "            log_std_min=-10.0, state_dependent_std=True, tanh_squash_distribution=True, final_fc_init_scale=1.0)\n",
    "\n",
    "        \n",
    "        critic_def = Critic(hidden_dims)\n",
    "        critic_keys  = jax.random.split(critic_key, NUM_CRITICS)\n",
    "        critic_params = jax.vmap(critic_def.init,in_axes=(0,None,None))(critic_keys, observations, actions)['params']\n",
    "        critics = jax.vmap(TrainState.create,in_axes=(None,0,None))(critic_def,critic_params,optax.adam(learning_rate=3e-4))\n",
    "\n",
    "        actor_params = actor_def.init(actor_key, observations)['params']\n",
    "        actor = TrainState.create(actor_def, actor_params, tx=optax.adam(learning_rate=3e-4,b1=0.5))\n",
    "        \n",
    "        temp_def = Temperature()\n",
    "        temp_params = temp_def.init(rng)['params']\n",
    "        temp = TrainState.create(temp_def, temp_params, tx=optax.sgd(learning_rate=5e-4,momentum=0.5))\n",
    "    \n",
    "        \n",
    "        if target_entropy is None:\n",
    "            target_entropy = - action_dim\n",
    "\n",
    "        config = flax.core.FrozenDict(dict(\n",
    "            discount=discount,\n",
    "            target_update_rate=tau,\n",
    "            target_entropy=target_entropy,\n",
    "            backup_entropy=backup_entropy,  \n",
    "            observations=observations,\n",
    "            actions=actions,          \n",
    "        ))\n",
    "\n",
    "        return SACAgent(rng, critic=critics, target_critic=critics, actor=actor, temp=temp, config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:51:28.065626: W external/xla/xla/service/gpu/nvptx_compiler.cc:679] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.103). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/tmpei_ix419/wandb/run-20240212_185129-sac_Ant-v4_586203_20240212_185128</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mahdikallel/no_entropy/runs/sac_Ant-v4_586203_20240212_185128' target=\"_blank\">sac_Ant-v4_586203</a></strong> to <a href='https://wandb.ai/mahdikallel/no_entropy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mahdikallel/no_entropy' target=\"_blank\">https://wandb.ai/mahdikallel/no_entropy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mahdikallel/no_entropy/runs/sac_Ant-v4_586203_20240212_185128' target=\"_blank\">https://wandb.ai/mahdikallel/no_entropy/runs/sac_Ant-v4_586203_20240212_185128</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra kwargs: {'max_steps': 1000000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 20656/1000000 [00:42<33:43, 484.02it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mahdi/Desktop/supersac/on_policy_sac.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mahdi/Desktop/supersac/on_policy_sac.ipynb#W1sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(policy_rollouts)\u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m:  \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mahdi/Desktop/supersac/on_policy_sac.ipynb#W1sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mdefault_matmul_precision(\u001b[39m'\u001b[39m\u001b[39mbfloat16\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mahdi/Desktop/supersac/on_policy_sac.ipynb#W1sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m         flattened_rollouts \u001b[39m=\u001b[39m flatten_rollouts(policy_rollouts)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mahdi/Desktop/supersac/on_policy_sac.ipynb#W1sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m         R2,bias \u001b[39m=\u001b[39m evaluate_many_critics(agent,policy_rollout\u001b[39m.\u001b[39mpolicy_return,flattened_rollouts)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mahdi/Desktop/supersac/on_policy_sac.ipynb#W1sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39m### Update actor ###\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/supersac/jaxrl_m/utils.py:94\u001b[0m, in \u001b[0;36mflatten_rollouts\u001b[0;34m(policy_rollouts)\u001b[0m\n\u001b[1;32m     91\u001b[0m     policy_rollouts\u001b[39m.\u001b[39mappend(policy_rollouts[\u001b[39m0\u001b[39m]) \u001b[39m## HOTFIX\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     n_policies \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m---> 94\u001b[0m merged_rollouts \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39;49mreduce(merge, policy_rollouts)\n\u001b[1;32m     95\u001b[0m merged_rollouts \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_map(\u001b[39mlambda\u001b[39;00m x:jnp\u001b[39m.\u001b[39mstack(jnp\u001b[39m.\u001b[39msplit(x,n_policies,axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)),merged_rollouts)\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape_tree\u001b[39m(tree, reference_tree,n_policies):\n",
      "File \u001b[0;32m~/Desktop/supersac/jaxrl_m/utils.py:84\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(x,y):\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m jax\u001b[39m.\u001b[39;49mtree_map(\u001b[39mlambda\u001b[39;49;00m x,y : jnp\u001b[39m.\u001b[39;49mvstack([x,y]),x,y)\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/tree_util.py:244\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    242\u001b[0m leaves, treedef \u001b[39m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    243\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m--> 244\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39;49munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;49;00m xs \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mall_leaves))\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/tree_util.py:244\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    242\u001b[0m leaves, treedef \u001b[39m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    243\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m--> 244\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;00m xs \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/Desktop/supersac/jaxrl_m/utils.py:84\u001b[0m, in \u001b[0;36mmerge.<locals>.<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(x,y):\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m jax\u001b[39m.\u001b[39mtree_map(\u001b[39mlambda\u001b[39;00m x,y : jnp\u001b[39m.\u001b[39;49mvstack([x,y]),x,y)\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1868\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype)\u001b[0m\n\u001b[1;32m   1866\u001b[0m   util\u001b[39m.\u001b[39mcheck_arraylike(\u001b[39m\"\u001b[39m\u001b[39mvstack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39mtup, emit_warning\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1867\u001b[0m   arrs \u001b[39m=\u001b[39m [atleast_2d(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m tup]\n\u001b[0;32m-> 1868\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate(arrs, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1854\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis, dtype)\u001b[0m\n\u001b[1;32m   1852\u001b[0m k \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[1;32m   1853\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(arrays_out) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1854\u001b[0m   arrays_out \u001b[39m=\u001b[39m [lax\u001b[39m.\u001b[39mconcatenate(arrays_out[i:i\u001b[39m+\u001b[39mk], axis)\n\u001b[1;32m   1855\u001b[0m                 \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(arrays_out), k)]\n\u001b[1;32m   1856\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_out[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1854\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1852\u001b[0m k \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[1;32m   1853\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(arrays_out) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1854\u001b[0m   arrays_out \u001b[39m=\u001b[39m [lax\u001b[39m.\u001b[39;49mconcatenate(arrays_out[i:i\u001b[39m+\u001b[39;49mk], axis)\n\u001b[1;32m   1855\u001b[0m                 \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(arrays_out), k)]\n\u001b[1;32m   1856\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_out[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:619\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(operands, dimension)\u001b[0m\n\u001b[1;32m    617\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(op, Array):\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m type_cast(Array, op)\n\u001b[0;32m--> 619\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate_p\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49moperands, dimension\u001b[39m=\u001b[39;49mdimension)\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/core.py:385\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    383\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39menable_checks\u001b[39m.\u001b[39mvalue \u001b[39mor\u001b[39;00m\n\u001b[1;32m    384\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 385\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/core.py:388\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 388\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    389\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/core.py:868\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 868\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/dispatch.py:128\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    126\u001b[0m   in_avals, in_shardings \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39munzip2([_arg_spec(a) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args])\n\u001b[1;32m    127\u001b[0m   in_tree \u001b[39m=\u001b[39m tree_util\u001b[39m.\u001b[39mtree_structure(args)\n\u001b[0;32m--> 128\u001b[0m   compiled_fun \u001b[39m=\u001b[39m xla_primitive_callable(\n\u001b[1;32m    129\u001b[0m       prim, in_avals, in_tree, OrigShardings(in_shardings), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    130\u001b[0m \u001b[39mexcept\u001b[39;00m pxla\u001b[39m.\u001b[39mDeviceAssignmentMismatchError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    131\u001b[0m   fails, \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39margs\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/util.py:284\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    283\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m   \u001b[39mreturn\u001b[39;00m cached(config\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49m_trace_context(), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/util.py:277\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mlru_cache(max_size)\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcached\u001b[39m(_, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 277\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/dispatch.py:161\u001b[0m, in \u001b[0;36mxla_primitive_callable\u001b[0;34m(prim, in_avals, in_tree, orig_in_shardings, **params)\u001b[0m\n\u001b[1;32m    156\u001b[0m flat_fun, out_tree \u001b[39m=\u001b[39m api_util\u001b[39m.\u001b[39mflatten_fun_nokwargs(wrapped_fun, in_tree)\n\u001b[1;32m    157\u001b[0m computation \u001b[39m=\u001b[39m sharded_lowering(\n\u001b[1;32m    158\u001b[0m     flat_fun, prim\u001b[39m.\u001b[39mname, donated_invars, keep_unused\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    159\u001b[0m     inline\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, in_avals\u001b[39m=\u001b[39min_avals, in_shardings\u001b[39m=\u001b[39morig_in_shardings\u001b[39m.\u001b[39mshardings,\n\u001b[1;32m    160\u001b[0m     lowering_parameters\u001b[39m=\u001b[39mmlir\u001b[39m.\u001b[39mLoweringParameters())\n\u001b[0;32m--> 161\u001b[0m compiled \u001b[39m=\u001b[39m computation\u001b[39m.\u001b[39;49mcompile()\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m xla_extension_version \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m192\u001b[39m:\n\u001b[1;32m    163\u001b[0m   \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mdisable_jit\u001b[39m.\u001b[39mvalue:\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2258\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[0;34m(self, compiler_options)\u001b[0m\n\u001b[1;32m   2256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(\u001b[39mself\u001b[39m, compiler_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m MeshExecutable:\n\u001b[1;32m   2257\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m compiler_options \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2258\u001b[0m     executable \u001b[39m=\u001b[39m UnloadedMeshExecutable\u001b[39m.\u001b[39;49mfrom_hlo(\n\u001b[1;32m   2259\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hlo, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_args,\n\u001b[1;32m   2260\u001b[0m         compiler_options\u001b[39m=\u001b[39;49mcompiler_options)\n\u001b[1;32m   2261\u001b[0m     \u001b[39mif\u001b[39;00m compiler_options \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2262\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m executable\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2606\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2603\u001b[0m       mesh \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mmesh  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   2604\u001b[0m       \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 2606\u001b[0m xla_executable, compile_options \u001b[39m=\u001b[39m _cached_compilation(\n\u001b[1;32m   2607\u001b[0m     hlo, name, mesh, spmd_lowering,\n\u001b[1;32m   2608\u001b[0m     tuple_args, auto_spmd_lowering, allow_prop_to_outputs,\n\u001b[1;32m   2609\u001b[0m     \u001b[39mtuple\u001b[39;49m(host_callbacks), backend, da, pmap_nreps,\n\u001b[1;32m   2610\u001b[0m     compiler_options_keys, compiler_options_values)\n\u001b[1;32m   2612\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(backend, \u001b[39m\"\u001b[39m\u001b[39mcompile_replicated\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   2613\u001b[0m   semantics_in_shardings \u001b[39m=\u001b[39m SemanticallyEqualShardings(in_shardings)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2513\u001b[0m, in \u001b[0;36m_cached_compilation\u001b[0;34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, _allow_propagation_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_keys, compiler_options_values)\u001b[0m\n\u001b[1;32m   2508\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m, compile_options\n\u001b[1;32m   2510\u001b[0m \u001b[39mwith\u001b[39;00m dispatch\u001b[39m.\u001b[39mlog_elapsed_time(\n\u001b[1;32m   2511\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFinished XLA compilation of \u001b[39m\u001b[39m{fun_name}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{elapsed_time}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2512\u001b[0m     fun_name\u001b[39m=\u001b[39mname, event\u001b[39m=\u001b[39mdispatch\u001b[39m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 2513\u001b[0m   xla_executable \u001b[39m=\u001b[39m compiler\u001b[39m.\u001b[39;49mcompile_or_get_cached(\n\u001b[1;32m   2514\u001b[0m       backend, computation, dev, compile_options, host_callbacks)\n\u001b[1;32m   2515\u001b[0m \u001b[39mreturn\u001b[39;00m xla_executable, compile_options\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/compiler.py:295\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, devices, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m    291\u001b[0m use_compilation_cache \u001b[39m=\u001b[39m (compilation_cache\u001b[39m.\u001b[39mis_initialized() \u001b[39mand\u001b[39;00m\n\u001b[1;32m    292\u001b[0m                          backend\u001b[39m.\u001b[39mplatform \u001b[39min\u001b[39;00m supported_platforms)\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m use_compilation_cache:\n\u001b[0;32m--> 295\u001b[0m   \u001b[39mreturn\u001b[39;00m backend_compile(backend, computation, compile_options,\n\u001b[1;32m    296\u001b[0m                          host_callbacks)\n\u001b[1;32m    298\u001b[0m \u001b[39mglobal\u001b[39;00m _cache_used\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _cache_used:\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/profiler.py:340\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    338\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    339\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    341\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/Desktop/supersac/.venv/lib/python3.10/site-packages/jax/_src/compiler.py:255\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    251\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    252\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import jax\n",
    "import tqdm\n",
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "from jaxrl_m.wandb import setup_wandb, default_wandb_config, get_flag_dict\n",
    "import wandb\n",
    "from jaxrl_m.evaluation import supply_rng, evaluate, flatten, EpisodeMonitor\n",
    "from jaxrl_m.dataset import ReplayBuffer\n",
    "from collections import deque\n",
    "from jax import config\n",
    "from jaxrl_m.utils import flatten_rollouts\n",
    "from jaxrl_m.evaluate_critic import evaluate_many_critics\n",
    "# config.update(\"jax_debug_nans\", True)\n",
    "# config.update(\"jax_enable_x64\", True)\n",
    "        \n",
    "from jaxrl_m.rollout import rollout_policy2,rollout_policy\n",
    "\n",
    "env_name='Ant-v4'\n",
    "seed=np.random.choice(1000000)\n",
    "eval_episodes=10\n",
    "batch_size = 256\n",
    "max_steps = int(1e6)\n",
    "start_steps = 10000                 \n",
    "log_interval = 5000\n",
    "\n",
    "wandb_config = {\n",
    "    'project': 'no_entropy',\n",
    "    'name': 'sac_{env_name}_{seed}'.format(env_name=env_name, seed=seed),\n",
    "    'hyperparam_dict':{'env_name':env_name,'seed':seed},\n",
    "}\n",
    "\n",
    "env = EpisodeMonitor(gym.make(env_name,max_episode_steps=625))\n",
    "eval_env = EpisodeMonitor(gym.make(env_name))\n",
    "setup_wandb(**wandb_config)\n",
    "\n",
    "example_transition = dict(\n",
    "    observations=env.observation_space.sample(),\n",
    "    actions=env.action_space.sample(),\n",
    "    rewards=0.0,\n",
    "    masks=1.0,\n",
    "    next_observations=env.observation_space.sample(),\n",
    "    discounts=1.0,\n",
    ")\n",
    "\n",
    "replay_buffer = ReplayBuffer.create(example_transition, size=int(1_000_000))\n",
    "actor_buffer = ReplayBuffer.create(example_transition, size=int(10e3))\n",
    "\n",
    "agent = create_learner(seed,\n",
    "                example_transition['observations'][None],\n",
    "                example_transition['actions'][None],\n",
    "                max_steps=max_steps,\n",
    "                #**FLAGS.config\n",
    "                )\n",
    "\n",
    "exploration_metrics = dict()\n",
    "obs,info = env.reset()    \n",
    "exploration_rng = jax.random.PRNGKey(0)\n",
    "i = 0\n",
    "unlogged_steps = 0\n",
    "policy_rollouts = deque([], maxlen=30)\n",
    "warmup = True\n",
    "R2 = jnp.ones(NUM_CRITICS)\n",
    "\n",
    "with tqdm.tqdm(total=max_steps) as pbar:\n",
    "    \n",
    "    while (i < max_steps):\n",
    "\n",
    "        warmup=(i < start_steps)\n",
    "        replay_buffer,actor_buffer,policy_rollout,policy_return,variance,undisc_policy_return,num_steps = rollout_policy(\n",
    "                                                                agent,env,exploration_rng,\n",
    "                                                                replay_buffer,actor_buffer,warmup=warmup,\n",
    "                                                                num_rollouts=NUM_ROLLOUTS,random=False,\n",
    "                                                                )\n",
    "        \n",
    "        if not warmup : policy_rollouts.append(policy_rollout)\n",
    "        unlogged_steps += num_steps\n",
    "        i+=num_steps\n",
    "        pbar.update(num_steps)\n",
    "            \n",
    "        if replay_buffer.size > start_steps and len(policy_rollouts)>0:\n",
    "        \n",
    "            ### Update critics ###\n",
    "            transitions = replay_buffer.get_all()\n",
    "            tmp = partial(jax.random.choice,a=replay_buffer.size, shape=(5000,512), replace=True)\n",
    "            idxs = jax.vmap(tmp)(jax.random.split(agent.rng, NUM_CRITICS))\n",
    "            agent, critic_update_info = agent.update_many_critics(transitions,idxs,5000,R2)\n",
    "\n",
    "            ### Update critic weights ## \n",
    "            if len(policy_rollouts)>=10:  \n",
    "                with jax.default_matmul_precision('bfloat16'):\n",
    "                                          \n",
    "                    flattened_rollouts = flatten_rollouts(policy_rollouts)\n",
    "                    R2,bias = evaluate_many_critics(agent,policy_rollout.policy_return,flattened_rollouts)\n",
    "        \n",
    "            ### Update actor ###\n",
    "            actor_batch = actor_buffer.get_all()      \n",
    "            agent, actor_update_info = agent.update_actor(actor_batch,R2)    \n",
    "            update_info = {**critic_update_info, **actor_update_info}\n",
    "            \n",
    "            if unlogged_steps > log_interval:\n",
    "                \n",
    "                policy_fn = partial(supply_rng(agent.sample_actions), temperature=0.0)\n",
    "                eval_info = evaluate(policy_fn, eval_env, num_episodes=eval_episodes)\n",
    "                \n",
    "                eval_metrics = {f'evaluation/{k}': v for k, v in eval_info.items()}\n",
    "                exploration_metrics = {f'exploration/disc_return': policy_return,'training/std': jnp.sqrt(variance)}\n",
    "                train_metrics = {f'training/{k}': v for k, v in update_info.items()}\n",
    "                train_metrics['training/undisc_return'] = undisc_policy_return\n",
    "                if len(policy_rollouts)>=10:\n",
    "                    R2_train_info = {'R2/max': jnp.max(R2),'R2/bias': bias[jnp.argmax(R2)],\n",
    "                                    \"R2/histogram\": wandb.Histogram(jnp.clip(R2,a_min=-1,a_max=1)),\n",
    "                                    }\n",
    "                    wandb.log(R2_train_info, step=int(i),commit=False)\n",
    "                wandb.log(exploration_metrics, step=int(i),commit=False)\n",
    "                wandb.log(train_metrics, step=int(i),commit=False)\n",
    "                wandb.log(eval_metrics, step=int(i),commit=True)\n",
    "                unlogged_steps = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
